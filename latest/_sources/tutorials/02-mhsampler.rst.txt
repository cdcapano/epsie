Example of creating and running a Metropolis-Hastings Sampler
=============================================================

In this notebook we will setup a sampler to sample a 2D Gaussian
distribution with mean :math:`\bar{x} = 2, \bar{y} = 5` and variance
:math:`\sigma_x^2 = 1`, :math:`\sigma_y^2 = 2`;
:math:`\sigma^2_{xy} = \sigma^2_{yx} = 0`, using a prior that is uniform
over :math:`x \in [-20, 20)`, :math:`y\in[-40, 40)`.

We will use Python's multiprocessing to evolve 12 chains using 4 cores.
We will demonstrate that resuming a sampler from it's state attribute
yields the same results as if we had run continuously. We then make a
plot of the posterior. Finally, we make an animation showing how the 12
chains moved.

.. code:: ipython3

    %matplotlib notebook
    from matplotlib import pyplot
    import numpy
    
    import epsie
    from epsie.samplers import MetropolisHastingsSampler
    import multiprocessing

Create the model to sample
--------------------------

***Note:*** Below we create a class with several functions to draw
samples from the prior and to evaluate the log posterior. This isn't
strictly necessary. The only thing the Sampler really requires is a
function that it can pass keyword arguments to and get back a tuple of
(log likelihood, log prior). However, setting things up as a class will
make it convenient to, e.g., draw random samples from the prior for the
starting positiions, as well as plot the model later on.

.. code:: ipython3

    from scipy import stats
    class Model(object):
        def __init__(self):
            # we'll use a 2D Gaussian for the likelihood distribution
            self.params = ['x', 'y']
            self.mean = [2., 5.]
            self.cov = [[1., 0.], [0., 2.]]
            self.likelihood_dist = stats.multivariate_normal(mean=self.mean,
                                                             cov=self.cov)
    
            # we'll just use a uniform prior
            self.prior_bounds = {'x': (-20., 20.),
                                 'y': (-40., 40.)}
            xmin = self.prior_bounds['x'][0]
            dx = self.prior_bounds['x'][1] - xmin
            ymin = self.prior_bounds['y'][0]
            dy = self.prior_bounds['y'][1] - ymin
            self.prior_dist = {'x': stats.uniform(xmin, dx),
                               'y': stats.uniform(ymin, dy)}
    
        def prior_rvs(self, size=None):
            return {p: self.prior_dist[p].rvs(size=size)
                    for p in self.params}
        
        def logprior(self, **kwargs):
            return sum([self.prior_dist[p].logpdf(kwargs[p]) for p in self.params])
        
        def loglikelihood(self, **kwargs):
            return self.likelihood_dist.logpdf([kwargs[p] for p in self.params])
        
        def __call__(self, **kwargs):
            logp = self.logprior(**kwargs)
            if logp == -numpy.inf:
                logl = None
            else:
                logl = self.loglikelihood(**kwargs)
            return logl, logp

.. code:: ipython3

    model = Model()

Setup and run the sampler
-------------------------

Create a pool of 4 parallel processes, then initialize the sampler using
the model we created above.

.. code:: ipython3

    nchains = 12
    nprocs = 4
    pool = multiprocessing.Pool(nprocs)
    #pool = None
    
    sampler = MetropolisHastingsSampler(model.params, model, nchains, pool=pool)

Now set the starting positions of the chains by drawing random variates
from the model's prior.

.. code:: ipython3

    sampler.start_position = model.prior_rvs(size=nchains)

Let's run it!
~~~~~~~~~~~~~

This will evolve each chain in the collection by 256 steps. This is
parallelized over the pool of processes.

.. code:: ipython3

    sampler.run(256)

Extract results
---------------

We can get the history of all of the chains using the ``.positions``
attribute. This will return a numpy structured array in which the fields
are the parameters names (in this case, ``'x'`` and ``'y'``), and with
shape ``nchains x niterations``:

.. code:: ipython3

    positions = sampler.positions
    print('sampler.positions: {}'.format(type(positions)))
    print('with fields: {}'.format(positions.dtype.names))
    print('and shape:', positions.shape)


.. parsed-literal::

    sampler.positions: <class 'numpy.ndarray'>
    with fields: ('x', 'y')
    and shape: (12, 256)


This (or any structured array returned by epsie) can be turned into a
dictionary of arrays, where the keys are the parameter names, using
``epsie.array2dict``:

.. code:: ipython3

    positions = epsie.array2dict(sampler.positions)
    print('sampler.positions: {} with keys/values:'.format(type(positions)))
    for param in sorted(positions):
        print('"{}": {} with shape {}'.format(param, type(positions[param]), positions[param].shape))


.. parsed-literal::

    sampler.positions: <class 'dict'> with keys/values:
    "x": <class 'numpy.ndarray'> with shape (12, 256)
    "y": <class 'numpy.ndarray'> with shape (12, 256)


We can also access the history of log likelihoods and log priors using
``sampler.stats``, as well as the acceptance ratios and which jumps were
accepted with ``sampler.acceptance``:

.. code:: ipython3

    stats = sampler.stats
    print('sampler.stats: {}'.format(type(stats)))
    print('with fields: {}'.format(stats.dtype.names))
    print('and shape:', stats.shape)


.. parsed-literal::

    sampler.stats: <class 'numpy.ndarray'>
    with fields: ('logl', 'logp')
    and shape: (12, 256)


.. code:: ipython3

    acceptance = sampler.acceptance
    print('sampler.acceptance: {}'.format(type(acceptance)))
    print('with fields: {}'.format(acceptance.dtype.names))
    print('and shape:', acceptance.shape)


.. parsed-literal::

    sampler.acceptance: <class 'numpy.ndarray'>
    with fields: ('acceptance_ratio', 'accepted')
    and shape: (12, 256)


If the model returned "blobs" (i.e., the model returns a dictionary
along with the logl and logp), then we can also access those using
``sampler.blobs``. Similar to ``positions``, this would also be a
dictionary of arrays with keys given by the names in the dictionary the
model returned. However, because our model above returns no blobs, in
this case we just get ``None``:

.. code:: ipython3

    print(sampler.blobs)


.. parsed-literal::

    None


The individual chains can be accessed using the ``.chains`` attribute:

.. code:: ipython3

    sampler.chains




.. parsed-literal::

    [<epsie.chain.chain.Chain at 0x1226544d0>,
     <epsie.chain.chain.Chain at 0x122654c90>,
     <epsie.chain.chain.Chain at 0x122654690>,
     <epsie.chain.chain.Chain at 0x12265a210>,
     <epsie.chain.chain.Chain at 0x122654ed0>,
     <epsie.chain.chain.Chain at 0x12265a950>,
     <epsie.chain.chain.Chain at 0x12265c850>,
     <epsie.chain.chain.Chain at 0x12266fcd0>,
     <epsie.chain.chain.Chain at 0x12265c890>,
     <epsie.chain.chain.Chain at 0x12265c110>,
     <epsie.chain.chain.Chain at 0x1226549d0>,
     <epsie.chain.chain.Chain at 0x12267cd50>]



Resume from a state
-------------------

The sampler can be checkpointed by getting its current state with
``sampler.state``. To demonstrate this, we'll get the current state of
the sampler, then run it for another set of iterations. We'll then
create a new sampler, and set it's state to the state we obtained from
first sampler. Running the same sampler for the same number of
iterations should produce the same results.

.. code:: ipython3

    # get the current state
    state = sampler.state

.. code:: ipython3

    # now advance the sampler for another 256 iterations
    sampler.run(256)

.. code:: ipython3

    # create a new sampler, but set it's state to what the original sampler's was after the first 250 iterations
    sampler2 = MetropolisHastingsSampler(model.params, model, nchains, pool=pool)
    sampler2.set_state(state)

.. code:: ipython3

    # now advance the new sampler for 256 iterations
    # note that we don't have to run set_start first, since the starting positions have been set by set_start
    sampler2.run(256)

.. code:: ipython3

    # compare the current results; they should be the same between sampler2 and sampler
    print('x:', (sampler.current_positions['x'] == sampler2.current_positions['x']).all())
    print('y:', (sampler.current_positions['y'] == sampler2.current_positions['y']).all())
    print('logl:', (sampler.current_stats['logl'] == sampler2.current_stats['logl']).all())
    print('logp:', (sampler.current_stats['logp'] == sampler2.current_stats['logp']).all())
    print('acceptance ratio:',
          (sampler.acceptance['acceptance_ratio'][:,-1] == sampler2.acceptance['acceptance_ratio'][:,-1]).all())
    print('accepted:',
          (sampler.acceptance['accepted'][:,-1] == sampler2.acceptance['accepted'][:,-1]).all())


.. parsed-literal::

    x: True
    y: True
    logl: True
    logp: True
    acceptance ratio: True
    accepted: True


Clearing memory and continuing
------------------------------

The history of results in memory can be cleared using ``.clear()``.
Running the sampler after a clear yields the same results as if no clear
had been done. This is useful for keeping memory usage down: you can
dump results to a file after some number of iterations, clear, then
continue.

To demonstrate this, we'll clear ``sampler2``, then run both ``sampler``
and ``sampler2`` for another 512 iterations. We'll then compare the
current results; they should be the same.

.. code:: ipython3

    sampler2.clear()

.. code:: ipython3

    sampler.run(512)
    sampler2.run(512)

.. code:: ipython3

    # compare the current results; they should be the same between sampler2 and sampler
    print('x:', (sampler.current_positions['x'] == sampler2.current_positions['x']).all())
    print('y:', (sampler.current_positions['y'] == sampler2.current_positions['y']).all())
    print('logl:', (sampler.current_stats['logl'] == sampler2.current_stats['logl']).all())
    print('logp:', (sampler.current_stats['logp'] == sampler2.current_stats['logp']).all())
    print('acceptance ratio:',
          (sampler.acceptance['acceptance_ratio'][:,-1] == sampler2.acceptance['acceptance_ratio'][:,-1]).all())
    print('accepted:',
          (sampler.acceptance['accepted'][:,-1] == sampler2.acceptance['accepted'][:,-1]).all())


.. parsed-literal::

    x: True
    y: True
    logl: True
    logp: True
    acceptance ratio: True
    accepted: True


Plot the posterior
------------------

Let's create a scatter plot of the posterior. For this, we'll need to
throw out some earlier samples for the burn-in period; we'll just assume
the first-half of the chains were burn in. We also need to calculate the
autocorrelation length of the chains in order to get independent
samples.

.. code:: ipython3

    def calculate_acf(data):
        """Calculates the autocorrelation of some data"""
        # zero the mean
        data = data - data.mean()
        # zero-pad to 2 * nearest power of 2
        newlen = int(2**(1+numpy.ceil(numpy.log2(len(data)))))
        x = numpy.zeros(newlen)
        x[:len(data)] = data[:]
        # correlate
        acf = numpy.correlate(x, x, mode='full')
        # drop corrupted region
        acf = acf[len(acf)//2:]
        # normalize
        acf /= acf[0]
        return acf
    
    def calculate_acl(data):
        """Calculates the autocorrelation length of some data.
        
        Algorithm used is from:
        N. Madras and A.D. Sokal, J. Stat. Phys. 50, 109 (1988).
        """
        # calculate the acf
        acf = calculate_acf(data)
        # now the ACL: Following from Sokal, this is estimated
        # as the first point where M*tau[k] <= k, where
        # tau = 2*cumsum(acf) - 1, and M is a tuneable parameter,
        # generally chosen to be = 5 (which we use here)
        m = 5
        cacf = 2.*numpy.cumsum(acf) - 1.
        win = m * cacf <= numpy.arange(len(cacf))
        if win.any():
            acl = int(numpy.ceil(cacf[numpy.where(win)[0][0]]))
        else:
            # data is too short to estimate the ACL, just choose
            # the length of the data
            acl = len(data)
        return acl

Since the chains are completely independent of each other, we can
calculate the ACL separately for each chain. However, if you'd like to
be more conservative, you can also just take the max over all of the
chains.

.. code:: ipython3

    # get the samples; recall that this is a dictionary of 
    # nchains x niterations arrays for each parameter
    samples = sampler.positions
    # as we said above, we'll assume the first half
    # of the chain was burn in
    burnin_iter = sampler.niterations // 2
    # set up arrays to store the ACL of each chain and
    # the thinned chains
    acls = numpy.zeros(nchains, dtype=int)
    thinned_arrays = {'x': [], 'y': []}
    # cycle over the chains, calculating the ACLs and thinning them
    for ii in range(nchains):
        # get the second half of the chains
        sx = samples['x'][ii, burnin_iter:]
        sy = samples['y'][ii, burnin_iter:]
        # compute the acl for each parameter
        aclx = calculate_acl(sx)
        acly = calculate_acl(sy)
        acl = max(aclx, acly)
        acls[ii] = acl
        # note that we'll thin the arrays starting from the
        # end to get the lastest results
        thinned_arrays['x'].append(sx[::-1][::acl][::-1])
        thinned_arrays['y'].append(sy[::-1][::acl][::-1])    

.. code:: ipython3

    # the ACL of each chain:
    print(acls)


.. parsed-literal::

    [23 10  6  9 13 12 19 10 18 24 24 19]


.. code:: ipython3

    # create a flattened posterior array
    posterior = {'x': numpy.concatenate(thinned_arrays['x']),
                 'y': numpy.concatenate(thinned_arrays['y'])}
    print("Number of independent samples:", posterior['x'].size)


.. parsed-literal::

    Number of independent samples: 480


.. code:: ipython3

    # histogram them
    fig, ax = pyplot.subplots()
    ax.hist(posterior['x'], bins=10, histtype='step', label='x')
    ax.hist(posterior['y'], bins=10, histtype='step', label='y')
    ax.legend()
    fig.show()



.. parsed-literal::

    <IPython.core.display.Javascript object>



.. raw:: html

    <img src="data:image/png;base64,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" width="639.8333333333334">


Let's check the mean and variance of our estimated posterior. These
should be :math:`\bar{x} \approx 2, \sigma^2_{x} \approx 1` and
:math:`\bar{y} \approx 5, \sigma^2_{y} \approx 2`:

.. code:: ipython3

    for param in posterior:
        s = posterior[param]
        print(param, 'mean: {}'.format(s.mean()), 'var: {}'.format(s.var()))


.. parsed-literal::

    x mean: 1.99478140402679 var: 0.8584428515335814
    y mean: 5.178616585856629 var: 1.9987894875419652


The values are close, but not exact. This isn't too surprising since we
only have :math:`\mathcal{O}(100)` samples. To get more samples, the
sampler can be run longer.

Create an animation of the results
----------------------------------

To visualize the results, we'll create an animation showing how the
chains evolved. We'll do this by plotting one point for each chain, with
each frame in the animation representing a single iteration.

***Note: To keep file size down, the animation has not been created for
the version of this notebook uploaded to the repository.***

.. code:: ipython3

    from matplotlib import animation

.. code:: ipython3

    # Prepare an array to create a density map showing the shape of the model posterior
    npts = 100
    xmean, ymean = model.likelihood_dist.mean
    xsig = model.likelihood_dist.cov[0,0]**0.5
    ysig = model.likelihood_dist.cov[1,1]**0.5
    X, Y = numpy.mgrid[xmean-3*xsig:xmean+3*xsig:complex(0, npts),
                       ymean-3*ysig:ymean+3*ysig:complex(0, npts)]
    Z = numpy.zeros(X.shape)
    for ii in range(Z.shape[0]):
        for jj in range(Z.shape[1]):
            logl, logp = model(x=X[ii,jj], y=Y[ii,jj])
            Z[ii, jj] = numpy.exp(logl+logp)

.. code:: ipython3

    # we'll just animate the first 200 iterations; change this to
    # nframes = xdata.shape[1]
    # if you want to see all iterations
    nframes = 200

.. code:: ipython3

    fig, ax = pyplot.subplots()
    
    positions = sampler.positions
    xdata = positions['x']
    ydata = positions['y']
    
    # Plot density map showing the shape of the true posterior density
    ax.imshow(numpy.rot90(Z), extent=[X.min(), X.max(), Y.min(), Y.max()],
              aspect='auto', cmap='binary', zorder=-3)
    
    # Put an x at the maximum posterior point
    ax.scatter(model.mean[0], model.mean[1], marker='x', color='w', s=10, zorder=-2)
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    # create the scatter points
    ptsize = 60
    
    # we'll include the last bufferlen number of steps a chain visited, having the size and transparency
    # exponentially damped with each new frame
    bufferlen = 16
    alphas = numpy.exp(-4*(numpy.arange(bufferlen))/float(bufferlen))
    sizes = ptsize * alphas
    #colors = numpy.array(['C{}'.format(ii) for ii in range(nchains)])
    colors = numpy.arange(nchains)
    plts = [ax.scatter(xdata[:, bufferlen-ii-1], ydata[:, bufferlen-ii-1], c=colors, s=sizes[ii],
                       edgecolors='w', linewidths=0.5,
                       alpha=alphas[ii], zorder=bufferlen-ii, marker='s' if ii==0 else 'o', cmap='jet')
            for ii in range(bufferlen)]
    # put a + showing the average of the chain positions at the current iteration
    meanplt = ax.scatter(xdata[:,0].mean(), ydata[:,0].mean(), marker='P', c='w', edgecolors='k', linewidths=0.5,
                         zorder=bufferlen+1)
    
    # add some text giving the iteration
    itertxt = 'Iteration {}'
    txt = ax.annotate(itertxt.format(1), (0.03, 0.94), xycoords='axes fraction')
    
    def animate(ii):
        txt.set_text(itertxt.format(ii+1))
        for jj,plt in enumerate(plts):
            plt.set_offsets(numpy.array([xdata[:, max(ii-jj, 0)], ydata[:, max(ii-jj, 0)]]).T)
        meanplt.set_offsets([xdata[:,ii].mean(), ydata[:,ii].mean()])
        # zoom in as it narrows on the result
        istart = max(ii-bufferlen, 0)
        # smooth it out a bit
        xmin = numpy.array([xdata[:, max(istart-kk, 0):].min() for kk in range(50)]).mean()
        xmax = numpy.array([xdata[:, max(istart-kk, 0):].max() for kk in range(50)]).mean()
        ymin = numpy.array([ydata[:, max(istart-kk, 0):].min() for kk in range(50)]).mean()
        ymax = numpy.array([ydata[:, max(istart-kk, 0):].max() for kk in range(50)]).mean()
        ax.set_xlim((1.1 if xmin < 1 else 0.9)*xmin, (0.9 if xmax < 1 else 1.1)*xmax)
        ax.set_ylim((1.1 if ymin < 1 else 0.9)*ymin, (0.9 if ymax < 1 else 1.1)*ymax)
    
    
    ani = animation.FuncAnimation(fig, animate, frames=nframes, interval=160, blit=True)

Save the animation:

.. code:: ipython3

    ani.save('chain_animation.mp4')

The result:

.. code:: ipython3

    %%HTML
    <video width="640" height="480" controls>
      <source src="chain_animation.mp4" type="video/mp4">
    </video>

