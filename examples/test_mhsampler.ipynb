{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of creating and running a Metropolis-Hastings Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will setup a sampler to sample a 2D Gaussian distribution with mean $\\bar{x} = 2, \\bar{y} = 5$ and variance $\\sigma_x^2 = 1$, $\\sigma_y^2 = 2$; $\\sigma^2_{xy} = \\sigma^2_{yx} = 0$, using a prior that is uniform over $x, y \\in [-20, 20)$.\n",
    "\n",
    "We will use Python's multiprocessing to evolve 12 chains using 4 cores. We will then make an animation showing how the 12 chains moved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "import randomgen\n",
    "\n",
    "import epsie\n",
    "from epsie.samplers import MetropolisHastingsSampler\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model to sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** Below we create a class with several functions to draw samples from the prior and to evaluate the log posterior. This isn't strictly necessary. The only thing the Sampler really requires is a function that it can pass keyword arguments to and get back a tuple of (log likelihood, log prior). However, setting things up as a class will make it convenient to, e.g., draw random samples from the prior for the starting positiions, as well as plot the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        # we'll use a 2D Gaussian for the likelihood distribution\n",
    "        self.params = ['x', 'y']\n",
    "        self.mean = [2., 5.]\n",
    "        self.cov = [[1., 0.], [0., 2.]]\n",
    "        self.likelihood_dist = stats.multivariate_normal(mean=self.mean,\n",
    "                                                         cov=self.cov)\n",
    "\n",
    "        # we'll just use a uniform prior\n",
    "        self.prior_bounds = {'x': (-20., 20.),\n",
    "                             'y': (-20., 20.)}\n",
    "        xmin = self.prior_bounds['x'][0]\n",
    "        dx = self.prior_bounds['x'][1] - xmin\n",
    "        ymin = self.prior_bounds['y'][0]\n",
    "        dy = self.prior_bounds['y'][1] - ymin\n",
    "        self.prior_dist = {'x': stats.uniform(xmin, dx),\n",
    "                           'y': stats.uniform(ymin, dy)}\n",
    "\n",
    "    def prior_rvs(self, size=None):\n",
    "        return {p: self.prior_dist[p].rvs(size=size)\n",
    "                for p in self.params}\n",
    "    \n",
    "    def logprior(self, **kwargs):\n",
    "        return sum([self.prior_dist[p].logpdf(kwargs[p]) for p in self.params])\n",
    "    \n",
    "    def loglikelihood(self, **kwargs):\n",
    "        return self.likelihood_dist.logpdf([kwargs[p] for p in self.params])\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        logp = self.logprior(**kwargs)\n",
    "        if logp == -numpy.inf:\n",
    "            logl = None\n",
    "        else:\n",
    "            logl = self.loglikelihood(**kwargs)\n",
    "        return logl, logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and run the sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pool of 4 parallel processes, then initialize the sampler using the model we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchains = 12\n",
    "nprocs = 4\n",
    "pool = multiprocessing.Pool(nprocs)\n",
    "\n",
    "sampler = MetropolisHastingsSampler(model.params, model, nchains, pool=pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the starting positions of the chains by drawing random variates from the model's prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.start_position = model.prior_rvs(size=nchains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will evolve each chain in the collection by 250 steps. This is parallelized over the pool of processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the history of all of the chains using the `.positions` attribute. This will return a numpy structured array in which the fields are the parameters names (in this case, `'x'` and `'y'`), and with shape `nchains x niterations`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.positions: <type 'numpy.ndarray'>\n",
      "with fields: ('x', 'y')\n",
      "and shape: (12, 250)\n"
     ]
    }
   ],
   "source": [
    "positions = sampler.positions\n",
    "print('sampler.positions: {}'.format(type(positions)))\n",
    "print('with fields: {}'.format(positions.dtype.names))\n",
    "print('and shape:', positions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This (or any structured array returned by epsie) can be turned into a dictionary of arrays, where the keys are the parameter names, using `epsie.array2dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.positions: <type 'dict'> with keys/values:\n",
      "\"x\": <type 'numpy.ndarray'> with shape (12, 250)\n",
      "\"y\": <type 'numpy.ndarray'> with shape (12, 250)\n"
     ]
    }
   ],
   "source": [
    "positions = epsie.array2dict(sampler.positions)\n",
    "print('sampler.positions: {} with keys/values:'.format(type(positions)))\n",
    "for param in sorted(positions):\n",
    "    print('\"{}\": {} with shape {}'.format(param, type(positions[param]), positions[param].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the history of log likelihoods and log priors using `sampler.stats`, as well as the acceptance ratios and which jumps were accepted with `sampler.acceptance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.stats: <type 'numpy.ndarray'>\n",
      "with fields: ('logl', 'logp')\n",
      "and shape: (12, 250)\n"
     ]
    }
   ],
   "source": [
    "stats = sampler.stats\n",
    "print('sampler.stats: {}'.format(type(stats)))\n",
    "print('with fields: {}'.format(stats.dtype.names))\n",
    "print('and shape:', stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampler.acceptance: <type 'numpy.ndarray'>\n",
      "with fields: ('acceptance_ratio', 'accepted')\n",
      "and shape: (12, 250)\n"
     ]
    }
   ],
   "source": [
    "acceptance = sampler.acceptance\n",
    "print('sampler.acceptance: {}'.format(type(acceptance)))\n",
    "print('with fields: {}'.format(acceptance.dtype.names))\n",
    "print('and shape:', acceptance.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model returned \"blobs\" (i.e., the model returns a dictionary along with the logl and logp), then we can also access those using `sampler.blobs`. Similar to `positions`, this would also be a dictionary of arrays with keys given by the names in the dictionary the model returned. However, because our model above returns no blobs, in this case we just get `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(sampler.blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual chains can be accessed using the `.chains` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<epsie.chain.chain.Chain at 0x1157122d0>,\n",
       " <epsie.chain.chain.Chain at 0x115712850>,\n",
       " <epsie.chain.chain.Chain at 0x115712ad0>,\n",
       " <epsie.chain.chain.Chain at 0x115729550>,\n",
       " <epsie.chain.chain.Chain at 0x1157296d0>,\n",
       " <epsie.chain.chain.Chain at 0x1156c6390>,\n",
       " <epsie.chain.chain.Chain at 0x1157397d0>,\n",
       " <epsie.chain.chain.Chain at 0x115739f90>,\n",
       " <epsie.chain.chain.Chain at 0x115743410>,\n",
       " <epsie.chain.chain.Chain at 0x115743a10>,\n",
       " <epsie.chain.chain.Chain at 0x115753110>,\n",
       " <epsie.chain.chain.Chain at 0x115753750>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume from a state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler can be checkpointed by getting its current state with `sampler.state`. To demonstrate this, we'll get the current state of the sampler, then run it for another set of iterations. We'll then create a new sampler, and set it's state to the state we obtained from first sampler. Running the same sampler for the same number of iterations should produce the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current state\n",
    "state = sampler.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now advance the sampler for another 250 iterations\n",
    "sampler.run(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new sampler, but set it's state to what the original sampler's was after the first 250 iterations\n",
    "sampler2 = MetropolisHastingsSampler(model.params, model, nchains, pool=pool)\n",
    "sampler2.set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now advance the new sampler for 250 iterations\n",
    "# note that we don't have to run set_start first, since the starting positions have been set by set_start\n",
    "sampler2.run(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: True\n",
      "y: True\n",
      "logl: True\n",
      "logp: True\n",
      "acceptance ratio: True\n",
      "accepted: True\n"
     ]
    }
   ],
   "source": [
    "# compare the current results; they should be the same between sampler2 and sampler\n",
    "print('x:', (sampler.current_positions['x'] == sampler2.current_positions['x']).all())\n",
    "print('y:', (sampler.current_positions['y'] == sampler2.current_positions['y']).all())\n",
    "print('logl:', (sampler.current_stats['logl'] == sampler2.current_stats['logl']).all())\n",
    "print('logp:', (sampler.current_stats['logp'] == sampler2.current_stats['logp']).all())\n",
    "print('acceptance ratio:',\n",
    "      (sampler.acceptance['acceptance_ratio'][:,-1] == sampler2.acceptance['acceptance_ratio'][:,-1]).all())\n",
    "print('accepted:',\n",
    "      (sampler.acceptance['accepted'][:,-1] == sampler2.acceptance['accepted'][:,-1]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing memory and continuing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The history of results in memory can be cleared using `.clear()`. Running the sampler after a clear yields the same results as if no clear had been done. This is useful for keeping memory usage down: you can dump results to a file after some number of iterations, clear, then continue.\n",
    "\n",
    "To demonstrate this, we'll clear `sampler2`, then run both `sampler` and `sampler2` for another 250 iterations. We'll then compare the current results; they should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler2.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run(250)\n",
    "sampler2.run(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: True\n",
      "y: True\n",
      "logl: True\n",
      "logp: True\n",
      "acceptance ratio: True\n",
      "accepted: True\n"
     ]
    }
   ],
   "source": [
    "# compare the current results; they should be the same between sampler2 and sampler\n",
    "print('x:', (sampler.current_positions['x'] == sampler2.current_positions['x']).all())\n",
    "print('y:', (sampler.current_positions['y'] == sampler2.current_positions['y']).all())\n",
    "print('logl:', (sampler.current_stats['logl'] == sampler2.current_stats['logl']).all())\n",
    "print('logp:', (sampler.current_stats['logp'] == sampler2.current_stats['logp']).all())\n",
    "print('acceptance ratio:',\n",
    "      (sampler.acceptance['acceptance_ratio'][:,-1] == sampler2.acceptance['acceptance_ratio'][:,-1]).all())\n",
    "print('accepted:',\n",
    "      (sampler.acceptance['accepted'][:,-1] == sampler2.acceptance['accepted'][:,-1]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an animation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the results, we'll create an animation showing how the chains evolved. We'll do this by plotting one point for each chain, with each frame in the animation representing a single iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note: To keep file size down, the animation has not been created for the version of this notebook uploaded to the repository.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an array to create a density map showing the shape of the model posterior\n",
    "npts = 100\n",
    "xmean, ymean = model.likelihood_dist.mean\n",
    "xsig = model.likelihood_dist.cov[0,0]**0.5\n",
    "ysig = model.likelihood_dist.cov[1,1]**0.5\n",
    "X, Y = numpy.mgrid[xmean-3*xsig:xmean+3*xsig:complex(0, npts),\n",
    "                   ymean-3*ysig:ymean+3*ysig:complex(0, npts)]\n",
    "Z = numpy.zeros(X.shape)\n",
    "for ii in range(Z.shape[0]):\n",
    "    for jj in range(Z.shape[1]):\n",
    "        logl, logp = model(x=X[ii,jj], y=Y[ii,jj])\n",
    "        Z[ii, jj] = numpy.exp(logl+logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll just animate the first 200 iterations; change this to\n",
    "# nframes = xdata.shape[1]\n",
    "# if you want to see all iterations\n",
    "nframes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "\n",
    "positions = sampler.positions\n",
    "xdata = positions['x']\n",
    "ydata = positions['y']\n",
    "\n",
    "# Plot density map showing the shape of the true posterior density\n",
    "ax.imshow(numpy.rot90(Z), extent=[X.min(), X.max(), Y.min(), Y.max()],\n",
    "          aspect='auto', cmap='binary', zorder=-3)\n",
    "\n",
    "# Put an x at the maximum posterior point\n",
    "ax.scatter(model.mean[0], model.mean[1], marker='x', color='w', s=10, zorder=-2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "# create the scatter points\n",
    "ptsize = 60\n",
    "\n",
    "# we'll include the last bufferlen number of steps a chain visited, having the size and transparency\n",
    "# exponentially damped with each new frame\n",
    "bufferlen = 16\n",
    "alphas = numpy.exp(-4*(numpy.arange(bufferlen))/float(bufferlen))\n",
    "sizes = ptsize * alphas\n",
    "#colors = numpy.array(['C{}'.format(ii) for ii in range(nchains)])\n",
    "colors = numpy.arange(nchains)\n",
    "plts = [ax.scatter(xdata[:, bufferlen-ii-1], ydata[:, bufferlen-ii-1], c=colors, s=sizes[ii],\n",
    "                   edgecolors='w', linewidths=0.5,\n",
    "                   alpha=alphas[ii], zorder=bufferlen-ii, marker='s' if ii==0 else 'o', cmap='jet')\n",
    "        for ii in range(bufferlen)]\n",
    "# put a + showing the average of the chain positions at the current iteration\n",
    "meanplt = ax.scatter(xdata[:,0].mean(), ydata[:,0].mean(), marker='P', c='w', edgecolors='k', linewidths=0.5,\n",
    "                     zorder=bufferlen+1)\n",
    "\n",
    "# add some text giving the iteration\n",
    "itertxt = 'Iteration {}'\n",
    "txt = ax.annotate(itertxt.format(1), (0.03, 0.94), xycoords='axes fraction')\n",
    "\n",
    "def animate(ii):\n",
    "    txt.set_text(itertxt.format(ii+1))\n",
    "    for jj,plt in enumerate(plts):\n",
    "        plt.set_offsets(numpy.array([xdata[:, max(ii-jj, 0)], ydata[:, max(ii-jj, 0)]]).T)\n",
    "    meanplt.set_offsets([xdata[:,ii].mean(), ydata[:,ii].mean()])\n",
    "    # zoom in as it narrows on the result\n",
    "    istart = max(ii-bufferlen, 0)\n",
    "    # smooth it out a bit\n",
    "    xmin = numpy.array([xdata[:, max(istart-kk, 0):].min() for kk in range(50)]).mean()\n",
    "    xmax = numpy.array([xdata[:, max(istart-kk, 0):].max() for kk in range(50)]).mean()\n",
    "    ymin = numpy.array([ydata[:, max(istart-kk, 0):].min() for kk in range(50)]).mean()\n",
    "    ymax = numpy.array([ydata[:, max(istart-kk, 0):].max() for kk in range(50)]).mean()\n",
    "    ax.set_xlim((1.1 if xmin < 1 else 0.9)*xmin, (0.9 if xmax < 1 else 1.1)*xmax)\n",
    "    ax.set_ylim((1.1 if ymin < 1 else 0.9)*ymin, (0.9 if ymax < 1 else 1.1)*ymax)\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=nframes, interval=160, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('chain_animation.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"chain_animation.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
